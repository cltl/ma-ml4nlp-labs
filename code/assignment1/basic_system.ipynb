{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic System\n",
    "\n",
    "This notebook provides code for implementing a very simple machine learning system for named entity recognition.\n",
    "It uses logistic regression and one feature (the token itself).\n",
    "Links to information about the packages are provided. Your job is to document the code and use it to train a system. You can then use your evaluation code to provide the first basic evaluation of your system.\n",
    "\n",
    "*Note:* In the next assignment, you can use this as a basis to experiment with more features and more machine learning methods.\n",
    "\n",
    "### About this Notebook:\n",
    "- The notebook is structured similarly to the assignment pdf. Each question contains suggestions to help guide you, but remember to follow the requirements in the PDF for your final answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# If you want to include other modules, you can add them here\n",
    "# Please note the recommendations on using modules in the Programming General Guidelines\n",
    "\n",
    "#recommended resource for examples: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load and inspect the data\n",
    "**Suggestions:**\n",
    " - Download the following files form from canvas ,and place them in the folder \"`./data/conll2003`\":\n",
    "   - `conll2003.train.conll`, `conll2003.test.conll`, `conll2003.dev.conll`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(inputfile):\n",
    "    \"\"\"TODO fill in docstring\"\"\"   \n",
    "    data = []\n",
    "    with open(inputfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(trainingfile):\n",
    "    \"\"\"TODO fill in docstring\"\"\"\n",
    "    data = []\n",
    "    targets = []\n",
    "    with open(trainingfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "                # NOTE: you can add inline comments when you feel the need, e.g. \"gold is in the last column\"\n",
    "                targets.append(components[-1])\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../data/conll2003/\"\n",
    "\n",
    "train_file = data_folder + \"conll2003.train.conll\"\n",
    "test_file = data_folder + \"conll2003.test.conll\"\n",
    "dev_file = data_folder + \"conll2003.dev.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = extract_features_and_labels(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data analysis: feature and label distributions\n",
    "**Suggestions:**\n",
    "\n",
    "- Inspect which unique NER labels there are and plot their distribution (tip: look into the `Counter()`)\n",
    "- Evaluate the samples per class to answer the questions in the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Evaluation\n",
    "\n",
    "**Suggestions:**\n",
    "- Create a sample file with the ground_truth features and labels `sample_gt.conll` and a sample prediction file with the predictions `sample_pred.conll`.\n",
    "- Create a function functions to calculate different metrics from two files: e.g. precision(), recall(), f-score(), confusion_matrix(). (Note you can use packages, e.g. `sklearn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Train and evaluate basic NERC system\n",
    "**Suggestions:**\n",
    "- Train the Logistic regression classifier on your dataset and evaluate the performance on your various metrics.\n",
    "- Transfer your code to a python file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(train_features, train_targets):\n",
    "    \"\"\"TODO fill in docstring\"\"\"\n",
    "    logreg = LogisticRegression()\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)\n",
    "    model = logreg.fit(features_vectorized, train_targets)\n",
    "    \n",
    "    return model, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(model, vec, inputdata, outputfile):\n",
    "    \"\"\"TODO fill in docstring\"\"\"\n",
    "    features = extract_features(inputdata)\n",
    "    features = vec.transform(features)\n",
    "    predictions = model.predict(features)\n",
    "    outfile = open(outputfile, 'w')\n",
    "    counter = 0\n",
    "    for line in open(inputdata, 'r'):\n",
    "        if len(line.rstrip('\\n').split()) > 0:\n",
    "            outfile.write(line.rstrip('\\n') + '\\t' + predictions[counter] + '\\n')\n",
    "            counter += 1\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (**optional**) 2.4.2 Convert to a python file:\n",
    "- This is part is optional for now but will be required for assignment 2, so it is good practice.\n",
    "\n",
    "Description:\n",
    "- To convert the code to a python file, you should place all the relevant functions in one `.py` file.\n",
    "- Add the following lines to the bottom, which ensure that if you call the function from a terminal, the lines within it will be exectued:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    \"\"\"TODO fill in docstring\"\"\"\n",
    "\n",
    "    #a very basic way for picking up commandline arguments\n",
    "    if argv is None:\n",
    "        argv = sys.argv\n",
    "        \n",
    "    #Note 1: argv[0] is the name of the python program if you run your program as: python program1.py arg1 arg2 arg3\n",
    "    #Note 2: sys.argv is simple, but gets messy if you need it for anything else than basic scenarios with few arguments\n",
    "    #you'll want to move to something better. e.g. argparse (easy to find online)\n",
    "    \n",
    "    \n",
    "    #you can replace the values for these with paths to the appropriate files for now, e.g. by specifying values in argv\n",
    "    #argv = ['mypython_program','','','']\n",
    "    trainingfile = argv[1]\n",
    "    inputfile = argv[2]\n",
    "    outputfile = argv[3]\n",
    "    \n",
    "    training_features, gold_labels = extract_features_and_labels(trainingfile)\n",
    "    ml_model, vec = create_classifier(training_features, gold_labels)\n",
    "    classify_data(ml_model, vec, inputfile, outputfile)\n",
    "\n",
    "# uncomment this when using this in a script    \n",
    "if __name__ == '__main__':\n",
    "    # Code below is executed when this python file is called from terminal\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that the first element of the list is not used \n",
    "# (since this is the `python command when the args are read from sys.argv)\n",
    "# make sure to complete the rest of the list assigned to args correctly\n",
    "args = ['python']\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
