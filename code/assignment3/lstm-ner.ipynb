{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for named entities\n",
    "\n",
    "Taken from: https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n",
    "\n",
    "Adapted to work with conll 2003 Named Entity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Run the imports below and install packages in case they are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input, optimizers\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# changed line:\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a random seed \n",
    "\n",
    "This increases the chances of getting similar results when training multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path to data and embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll data\n",
    "path_train ='../../../../lstm-test/conll2003.train.conll' #adapt\n",
    "path_eval = '../../../../lstm-test/conll2003.dev.conll' # adapt\n",
    "paths = [path_train, path_eval]\n",
    "\n",
    "# change to test if you are evaluating on test:\n",
    "eval_split = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model output path\n",
    "output_path = 'lsmt-out.csv' # adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "path_emb = '/Users/piasommerauer/Data/dsm/word2vec/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Run the cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connll data\n",
    "\n",
    "def convert_data(paths):\n",
    "    \n",
    "    data = []\n",
    "    sent_id = 1\n",
    "    for path in paths:\n",
    "        split = path.split('.')[-2]\n",
    "        with open(path) as infile:\n",
    "            lines = infile.read().split('\\n')\n",
    "        for n, line in enumerate(lines):\n",
    "            ll = line.split('\\t')\n",
    "            if len(ll) > 2:\n",
    "                d = dict()\n",
    "                d['Sentence #'] = f'Sentence: {sent_id}'\n",
    "                d['Word'] = ll[0]\n",
    "                d['POS'] = ll[1]\n",
    "                d['Tag'] = ll[-1]\n",
    "                d['Split'] = split\n",
    "                data.append(d)\n",
    "\n",
    "            else:\n",
    "                sent_id += 1\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "data = convert_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #     Word  POS     Tag  Split\n",
       "0  Sentence: 1       EU  NNP   B-ORG  train\n",
       "1  Sentence: 1  rejects  VBZ       O  train\n",
       "2  Sentence: 1   German   JJ  B-MISC  train\n",
       "3  Sentence: 1     call   NN       O  train\n",
       "4  Sentence: 1       to   TO       O  train"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254978</th>\n",
       "      <td>Sentence: 17291</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254979</th>\n",
       "      <td>Sentence: 17292</td>\n",
       "      <td>--</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254980</th>\n",
       "      <td>Sentence: 17292</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254981</th>\n",
       "      <td>Sentence: 17292</td>\n",
       "      <td>Newsroom</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254982</th>\n",
       "      <td>Sentence: 17292</td>\n",
       "      <td>880-2-506363</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #          Word  POS    Tag Split\n",
       "254978  Sentence: 17291             .    .      O   dev\n",
       "254979  Sentence: 17292            --    :      O   dev\n",
       "254980  Sentence: 17292         Dhaka  NNP  B-ORG   dev\n",
       "254981  Sentence: 17292      Newsroom  NNP  I-ORG   dev\n",
       "254982  Sentence: 17292  880-2-506363   CD      O   dev"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map tokens and labels to indices\n",
    "\n",
    "No need to understand this, just run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26883\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# map tokens and labels to indices\n",
    "\n",
    "def get_dict_map(data, token_or_tag, embedding_model=None):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}   \n",
    "    \n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')\n",
    "print(len(token2idx))\n",
    "print(len(tag2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating embeddings\n",
    "\n",
    "Change the path of the embedding model below to load your own GoogleNews vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "# Change path to your path\n",
    "w2v_model = KeyedVectors.load_word2vec_format(path_emb, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26884, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix with zero vectors for oov words\n",
    "emb_dim = 300\n",
    "embedding_matrix = np.zeros((len(token2idx) + 1, emb_dim))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in token2idx.items():\n",
    "    # You may have to change the following line to:\n",
    "    # if word in w2v_model:\n",
    "    if word in w2v_model.key_to_index:\n",
    "        embedding_vector = w2v_model[word]\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "        # If you want to check OOV words:\n",
    "        #print('couldnt find:', word, i)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26884, 300)\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions, store number of vector dimensions in variable\n",
    "print(embedding_matrix.shape)\n",
    "emb_dim = embedding_matrix.shape[1]\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Split</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>train</td>\n",
       "      <td>3992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>3974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>train</td>\n",
       "      <td>1386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>22339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "      <td>train</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #     Word  POS     Tag  Split  Word_idx  Tag_idx\n",
       "0  Sentence: 1       EU  NNP   B-ORG  train      3992        6\n",
       "1  Sentence: 1  rejects  VBZ       O  train      3974        1\n",
       "2  Sentence: 1   German   JJ  B-MISC  train      1386        2\n",
       "3  Sentence: 1     call   NN       O  train     22339        1\n",
       "4  Sentence: 1       to   TO       O  train      1178        1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add index info to dataframe\n",
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-c081495d77d6>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
       "      <td>[NNP, VBZ, JJ, NN, TO, VB, JJ, NN, .]</td>\n",
       "      <td>[B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]</td>\n",
       "      <td>[3992, 3974, 1386, 22339, 1178, 25230, 5188, 1...</td>\n",
       "      <td>[6, 1, 2, 1, 1, 1, 2, 1, 1]</td>\n",
       "      <td>[train, train, train, train, train, train, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[But, Fischler, agreed, to, review, his, propo...</td>\n",
       "      <td>[CC, NNP, VBD, TO, VB, PRP$, NN, IN, DT, NNP, ...</td>\n",
       "      <td>[O, B-PER, O, O, O, O, O, O, O, B-ORG, O, O, O...</td>\n",
       "      <td>[19572, 21568, 7872, 1178, 959, 9577, 21556, 6...</td>\n",
       "      <td>[1, 5, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[train, train, train, train, train, train, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[The, Syrians, are, confused, ,, they, are, de...</td>\n",
       "      <td>[DT, NNPS, VBP, VBN, ,, PRP, VBP, RB, JJ, ,, C...</td>\n",
       "      <td>[O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[19394, 8192, 20553, 6082, 9921, 17002, 20553,...</td>\n",
       "      <td>[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[train, train, train, train, train, train, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[The, youth, side, replied, with, 246, for, se...</td>\n",
       "      <td>[DT, NN, NN, VBD, IN, CD, IN, CD, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[19394, 2995, 8835, 11003, 26122, 10050, 6701,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[train, train, train, train, train, train, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[Men, 's, 3,000, metres, :]</td>\n",
       "      <td>[NN, POS, CD, NNS, :]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[23556, 3067, 24399, 5163, 4601]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[train, train, train, train, train]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "0      Sentence: 1  [EU, rejects, German, call, to, boycott, Briti...   \n",
       "1     Sentence: 10  [But, Fischler, agreed, to, review, his, propo...   \n",
       "2    Sentence: 100  [The, Syrians, are, confused, ,, they, are, de...   \n",
       "3   Sentence: 1000  [The, youth, side, replied, with, 246, for, se...   \n",
       "4  Sentence: 10000                        [Men, 's, 3,000, metres, :]   \n",
       "\n",
       "                                                 POS  \\\n",
       "0              [NNP, VBZ, JJ, NN, TO, VB, JJ, NN, .]   \n",
       "1  [CC, NNP, VBD, TO, VB, PRP$, NN, IN, DT, NNP, ...   \n",
       "2  [DT, NNPS, VBP, VBN, ,, PRP, VBP, RB, JJ, ,, C...   \n",
       "3               [DT, NN, NN, VBD, IN, CD, IN, CD, .]   \n",
       "4                              [NN, POS, CD, NNS, :]   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0          [B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]   \n",
       "1  [O, B-PER, O, O, O, O, O, O, O, B-ORG, O, O, O...   \n",
       "2  [O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "3                        [O, O, O, O, O, O, O, O, O]   \n",
       "4                                    [O, O, O, O, O]   \n",
       "\n",
       "                                            Word_idx  \\\n",
       "0  [3992, 3974, 1386, 22339, 1178, 25230, 5188, 1...   \n",
       "1  [19572, 21568, 7872, 1178, 959, 9577, 21556, 6...   \n",
       "2  [19394, 8192, 20553, 6082, 9921, 17002, 20553,...   \n",
       "3  [19394, 2995, 8835, 11003, 26122, 10050, 6701,...   \n",
       "4                   [23556, 3067, 24399, 5163, 4601]   \n",
       "\n",
       "                                             Tag_idx  \\\n",
       "0                        [6, 1, 2, 1, 1, 1, 2, 1, 1]   \n",
       "1  [1, 5, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4                                    [1, 1, 1, 1, 1]   \n",
       "\n",
       "                                               Split  \n",
       "0  [train, train, train, train, train, train, tra...  \n",
       "1  [train, train, train, train, train, train, tra...  \n",
       "2  [train, train, train, train, train, train, tra...  \n",
       "3  [train, train, train, train, train, train, tra...  \n",
       "4                [train, train, train, train, train]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group data by sentences\n",
    "# Fill na\n",
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "# Groupby and collect columns\n",
    "data_group = data_fillna.groupby(\n",
    "['Sentence #'],as_index=False\n",
    ")['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx', 'Split'].agg(lambda x: list(x))\n",
    "# Visualise data\n",
    "data_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26883\n",
      "padding 113\n",
      "train_tokens length: 14041 \n",
      "train_tokens length: 14041 \n",
      "val_tokens: 3250 \n",
      "val_tags: 3250\n"
     ]
    }
   ],
   "source": [
    "# Change eval_split from 'dev' to test to run on test data\n",
    "def get_pad_train_test_val(data_group, data, eval_split='dev'):\n",
    "\n",
    "    #get max token and tag length\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    print(n_token)\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int64', padding='post', value= 26883)\n",
    "    print('padding', len(pad_tokens[0]))\n",
    "    # I used the code below to check the if the padded vectors are set to 0:\n",
    "#     for token in pad_tokens:\n",
    "#         print(token[-1])\n",
    "# #         print(embedding_matrix[token[-1]])\n",
    "#         break\n",
    "\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int64', padding='post', value= tag2idx[\"O\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    \n",
    "    train_tokens = []\n",
    "    dev_tokens = []\n",
    "    train_tags = []\n",
    "    dev_tags = []\n",
    "    for i, row in data_group.iterrows():\n",
    "        if 'train' in row['Split']:\n",
    "            train_tokens.append(pad_tokens[i])\n",
    "            train_tags.append(pad_tags[i])\n",
    "        elif eval_split in row['Split']:\n",
    "            #dev_idx.append(i)\n",
    "            dev_tokens.append(pad_tokens[i])\n",
    "            dev_tags.append(pad_tags[i])\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tokens length:', len(train_tokens),\n",
    "        #'\\ntest_tokens length:', len(test_tokens),\n",
    "        #'\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(dev_tokens),\n",
    "        '\\nval_tags:', len(dev_tags))\n",
    " \n",
    "    return np.array(train_tokens), np.array(dev_tokens),  np.array(train_tags), np.array(dev_tags)\n",
    "\n",
    "train_tokens, dev_tokens,  train_tags, dev_tags = get_pad_train_test_val(data_group, data, eval_split= eval_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  26884 \n",
      "output_dim:  300 \n",
      "input_length:  113 \n",
      "n_tags:  9\n",
      "emb dim 300\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list()))) +1\n",
    "output_dim = emb_dim # number of dimensions\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', \n",
    "      input_dim, '\\noutput_dim: ', \n",
    "      output_dim, '\\ninput_length: ', \n",
    "      input_length, '\\nn_tags: ', n_tags)\n",
    "print('emb dim', emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model(embedding_matrix, embedding_dim):\n",
    "    \n",
    "    model = Sequential()\n",
    "    #token2idx\n",
    "    # Add Embedding layer original, trainable\n",
    "    #model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "    print(len(token2idx))\n",
    "    embedding_layer = Embedding(len(token2idx)+1 ,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            # make max sent length a variable\n",
    "                            input_length=input_length,\n",
    "                            trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    # Add LSTM\n",
    "    # Pia decided to remove this\n",
    "#     model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    # Pia: replaced relu with sigmoid \n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"sigmoid\")))\n",
    "\n",
    " \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    # set epochs to 3 (from 25) (you can change this)\n",
    "    for i in range(3):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=200, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "embedding_dim = 300 # dimensions of the word2vec vectors\n",
    "model_bilstm_lstm = get_bilstm_lstm_model(embedding_matrix, embedding_dim)\n",
    "plot_model(model_bilstm_lstm)\n",
    "# change to val_tokens to try out training on val set\n",
    "results['with_add_lstm'] = train_model(train_tokens, train_tags, model_bilstm_lstm)\n",
    "#results['with_add_lstm'] = train_model(dev_tokens, dev_tags, model_bilstm_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "The code below evaluates your model on the development data using accuracy (which is not very indicative on this task. To get better insights, store the model output and run your own evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "# Shows accuracy:\n",
    "# Careful: Really high even if the model \n",
    "# only predicts the majority class\n",
    "print(\"Evaluate on test data\")\n",
    "# test: test_tokens, test_tags\n",
    "\n",
    "#print(train_tags[:5])\n",
    "results = model_bilstm_lstm.evaluate(dev_tokens, np.array(dev_tags), batch_size=1)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on development set\n",
    "y_pred = model_bilstm_lstm.predict(dev_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dimension index with highest prob (--> label)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_dev =  np.argmax(dev_tags, axis=-1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model predicts more than the majority class\n",
    "pred_labels = []\n",
    "for tag in y_pred:\n",
    "    for i in tag:\n",
    "        label = idx2tag[i]\n",
    "        #continue\n",
    "        if label != 'O':\n",
    "            print(label)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions per token:\n",
    "# map labels back to tokens\n",
    "\n",
    "def output_to_file(dev_tokens, y_pred, output_path):\n",
    "    \n",
    "    with open(output_path, 'w') as outfile:\n",
    "        outfile.write('token\\tNER\\n')\n",
    "        for token,  preds in zip(dev_tokens, y_pred):\n",
    "            for tok, pred in zip(token, dev_tag, preds):\n",
    "                # igonre padding:\n",
    "                if tok in idx2token:\n",
    "                    tok_str = idx2token[tok]\n",
    "                    outfile.write(f'{tok_str}\\t{idx2tag[pred]}\\n')\n",
    "    \n",
    "output_to_file(dev_tokens, y_pred, output_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
